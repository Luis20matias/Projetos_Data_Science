{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portuguese spell checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the file (corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "4w8iNgp59SZ1",
    "outputId": "960c5048-c28e-4609-81ae-b05168a3058d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "with open(\"artigos.txt\", \"r\") as file:\n",
    "    articles = file.read()\n",
    "\n",
    "print(articles[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CMiQsS__KL8a",
    "outputId": "babbfdda-10f6-410c-b5be-20b66d54cfae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2605046"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of letters and not the number of words\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jRJUTZfnK-CI",
    "outputId": "dc091a95-8a7a-4472-fd39-edc5f77907b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2bc3aDULNe4"
   },
   "outputs": [],
   "source": [
    "text_example = \"Hello, are you ok?\"\n",
    "tokens = text_example.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "e7kg1lbNLmnt",
    "outputId": "1ce751b8-a4d1-4f78-e2e0-c623ee4602c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZTJCUj_wLqJ9",
    "outputId": "fe8de022-3543-4c4e-ce12-1d9b24b863e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', 'are', 'you', 'ok?']\n"
     ]
    }
   ],
   "source": [
    "# The Split separates with the punctuation\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Natural Language Toolkit (NLTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "5H3VpslwSHc0",
    "outputId": "6eff7d01-1dd9-4156-9c7e-3c89b4f9342a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'are', 'you', 'ok', '?']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# nltk.download('punkt') # It is needed to download some packages\n",
    "separated_words = nltk.tokenize.word_tokenize(text_example)\n",
    "print(separated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pzMCe-2FE4lS",
    "outputId": "d56dced4-b4bb-4e16-f08d-f3da5b5fd6ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It includes the symbols\n",
    "len(separated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "898inn-nGTOM",
    "outputId": "63cf2e9d-496f-479e-b07c-296c7ce85236"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The isalpha() method returns True if all the characters are alphabet letters (a-z).\n",
    "'./'.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tjLIUpcRF0gG",
    "outputId": "f73268e6-a436-4942-88a0-2ac23813a80a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'are', 'you', 'ok']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a function to get just the words in a token list\n",
    "def separate_words(tokens_list):\n",
    "    words_list = []\n",
    "    for token in tokens_list:\n",
    "        if token.isalpha():\n",
    "            words_list.append(token)\n",
    "    return words_list\n",
    "\n",
    "separate_words(separated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aoQ-5crVHFgx",
    "outputId": "bd10fb64-b114-45c0-dd9d-3c13d506f03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words is 403031\n"
     ]
    }
   ],
   "source": [
    "list_tokens = nltk.tokenize.word_tokenize(articles)\n",
    "words_list = separate_words(list_tokens)\n",
    "print(f\"The number of words is {len(words_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "C9yf23zIfsg6",
    "outputId": "5f6989c3-57f9-4470-a738-3a325678dbfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'Temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(words_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "SHsX7m5WfzjU",
    "outputId": "feb40c82-312c-4247-df47-b6d0638c550d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no']\n"
     ]
    }
   ],
   "source": [
    "# Creating a function to normalize all the words (put every words in lowercase)\n",
    "def normalization(words_list):\n",
    "    normalized_list = []\n",
    "    for word in words_list:\n",
    "        normalized_list.append(word.lower())\n",
    "    return normalized_list\n",
    "\n",
    "normalized_list = normalization(words_list)\n",
    "print(normalized_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aiaBKar-nBRA",
    "outputId": "a8225441-8578-4ef7-a3a6-f6ba331f354d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18464"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Took off the repeated words // This is the number of words that our model will learn (This can be limitation)\n",
    "len(set(normalized_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GRqG3LbXOa0T",
    "outputId": "cc8013f1-5fb9-429e-9404-48cd19aaff67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('l', 'gica')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_test = \"lgica\"\n",
    "(word_test[:1],word_test[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the spell checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "A4iflAEdOERO",
    "outputId": "41d7e3f1-d4d2-4809-c1bd-3aa53aa32a8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'álgica', 'âlgica', 'àlgica', 'ãlgica', 'élgica', 'êlgica', 'èlgica', 'ẽlgica', 'ílgica', 'îlgica', 'ìlgica', 'ĩlgica', 'ólgica', 'ôlgica', 'õlgica', 'òlgica', 'úlgica', 'ûlgica', 'ùlgica', 'ũlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'lágica', 'lâgica', 'làgica', 'lãgica', 'légica', 'lêgica', 'lègica', 'lẽgica', 'lígica', 'lîgica', 'lìgica', 'lĩgica', 'lógica', 'lôgica', 'lõgica', 'lògica', 'lúgica', 'lûgica', 'lùgica', 'lũgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgáica', 'lgâica', 'lgàica', 'lgãica', 'lgéica', 'lgêica', 'lgèica', 'lgẽica', 'lgíica', 'lgîica', 'lgìica', 'lgĩica', 'lgóica', 'lgôica', 'lgõica', 'lgòica', 'lgúica', 'lgûica', 'lgùica', 'lgũica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiáca', 'lgiâca', 'lgiàca', 'lgiãca', 'lgiéca', 'lgiêca', 'lgièca', 'lgiẽca', 'lgiíca', 'lgiîca', 'lgiìca', 'lgiĩca', 'lgióca', 'lgiôca', 'lgiõca', 'lgiòca', 'lgiúca', 'lgiûca', 'lgiùca', 'lgiũca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicáa', 'lgicâa', 'lgicàa', 'lgicãa', 'lgicéa', 'lgicêa', 'lgicèa', 'lgicẽa', 'lgicía', 'lgicîa', 'lgicìa', 'lgicĩa', 'lgicóa', 'lgicôa', 'lgicõa', 'lgicòa', 'lgicúa', 'lgicûa', 'lgicùa', 'lgicũa', 'lgicça', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaá', 'lgicaâ', 'lgicaà', 'lgicaã', 'lgicaé', 'lgicaê', 'lgicaè', 'lgicaẽ', 'lgicaí', 'lgicaî', 'lgicaì', 'lgicaĩ', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaò', 'lgicaú', 'lgicaû', 'lgicaù', 'lgicaũ', 'lgicaç']\n"
     ]
    }
   ],
   "source": [
    "word_example = \"lgica\"\n",
    "\n",
    "def insert_letters(slices):\n",
    "    new_words = []\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
    "    for left_word, right_word in slices:\n",
    "        for letter in letters:\n",
    "            new_words.append(left_word + letter + right_word)\n",
    "    return new_words\n",
    "\n",
    "def words_generator(word):\n",
    "    slices = []\n",
    "    for i in range(len(word)+1):\n",
    "        slices.append((word[:i], word[i:]))\n",
    "    generated_words = insert_letters(slices)\n",
    "    return generated_words\n",
    "\n",
    "generated_words = words_generator(word_example)\n",
    "print(generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ot_OdS6JbHsJ"
   },
   "outputs": [],
   "source": [
    "def spell_checker(word):\n",
    "    generated_words = words_generator(word)\n",
    "    corrected_word = max(generated_words, key=probability)\n",
    "    return corrected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "52O3NR0TUsOD",
    "outputId": "acacdd91-8612-4b37-f284-c957c231c994"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 15502),\n",
       " ('o', 14056),\n",
       " ('que', 12230),\n",
       " ('a', 11099),\n",
       " ('e', 10501),\n",
       " ('para', 7710),\n",
       " ('um', 6367),\n",
       " ('é', 5899),\n",
       " ('uma', 5220),\n",
       " ('do', 5124)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = nltk.FreqDist(normalized_list) # frequency of each word\n",
    "all_words = len(normalized_list)\n",
    "frequency.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rOE_KSwhWFtj",
    "outputId": "88015153-342c-4b1f-8723-5b0ac4d5e3f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is used global variables just in this cases, because it will be used this function many times.\n",
    "def  probability(generated_words):\n",
    "    return frequency[generated_words]/all_words \n",
    "\n",
    "probability(\"logica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iRZQIUebW5Bx",
    "outputId": "810283b9-cdac-4a8c-bcd3-9e2a59f8ffce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023819507680550628"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " probability(\"lógica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZbyrWgi8XFaQ",
    "outputId": "57b01d9e-f539-4d36-f8eb-330478fa6090"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_checker(word_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wwehYS7MdaTB",
    "outputId": "4c6eee26-3683-4cae-da24-a6118946bed1"
   },
   "outputs": [],
   "source": [
    "def create_test_data(file_name):\n",
    "    list_test_words = []\n",
    "    file = open(file_name, \"r\")\n",
    "    for line in file:\n",
    "        correct, wrong = line.split()\n",
    "        list_test_words.append((correct, wrong))\n",
    "    f.close()\n",
    "    return list_test_words\n",
    "\n",
    "test_list = create_test_data(\"palavras.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an evaluator for the spell checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OdtegimbivRj",
    "outputId": "a8623c69-b594-4d1f-f113-582bda6bd012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08% of 186 words\n"
     ]
    }
   ],
   "source": [
    "def evaluator(tests):\n",
    "    word_number = len(tests)\n",
    "    got_right = 0\n",
    "    for correct, wrong in tests:\n",
    "        corrected_word = spell_checker(wrong)\n",
    "        if corrected_word == correct:\n",
    "            got_right += 1\n",
    "    hit_rate = round(got_right*100/word_number, 2)\n",
    "    print(f\"{hit_rate}% of {word_number} words\")\n",
    "\n",
    "evaluator(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting a character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CcQQ8ygzmm5h"
   },
   "outputs": [],
   "source": [
    "def deleting_character(slices):\n",
    "    new_words = []\n",
    "    for left, right in slices:\n",
    "        new_words.append(left + right[1:])\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the word generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "7giRbXiZfWEq",
    "outputId": "c2a627c1-dbf7-4bc8-f440-31188ea77f20"
   },
   "outputs": [],
   "source": [
    "def words_generator(word):\n",
    "    slices = []\n",
    "    for i in range(len(word)+1):\n",
    "        slices.append((word[:i], word[i:]))\n",
    "    generated_words = insert_letters(slices)\n",
    "    generated_words += deleting_character(slices)\n",
    "    return generated_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alóigica', 'blóigica', 'clóigica', 'dlóigica', 'elóigica', 'flóigica', 'glóigica', 'hlóigica', 'ilóigica', 'jlóigica', 'klóigica', 'llóigica', 'mlóigica', 'nlóigica', 'olóigica', 'plóigica', 'qlóigica', 'rlóigica', 'slóigica', 'tlóigica', 'ulóigica', 'vlóigica', 'wlóigica', 'xlóigica', 'ylóigica', 'zlóigica', 'álóigica', 'âlóigica', 'àlóigica', 'ãlóigica', 'élóigica', 'êlóigica', 'èlóigica', 'ẽlóigica', 'ílóigica', 'îlóigica', 'ìlóigica', 'ĩlóigica', 'ólóigica', 'ôlóigica', 'õlóigica', 'òlóigica', 'úlóigica', 'ûlóigica', 'ùlóigica', 'ũlóigica', 'çlóigica', 'laóigica', 'lbóigica', 'lcóigica', 'ldóigica', 'leóigica', 'lfóigica', 'lgóigica', 'lhóigica', 'lióigica', 'ljóigica', 'lkóigica', 'llóigica', 'lmóigica', 'lnóigica', 'loóigica', 'lpóigica', 'lqóigica', 'lróigica', 'lsóigica', 'ltóigica', 'luóigica', 'lvóigica', 'lwóigica', 'lxóigica', 'lyóigica', 'lzóigica', 'láóigica', 'lâóigica', 'làóigica', 'lãóigica', 'léóigica', 'lêóigica', 'lèóigica', 'lẽóigica', 'líóigica', 'lîóigica', 'lìóigica', 'lĩóigica', 'lóóigica', 'lôóigica', 'lõóigica', 'lòóigica', 'lúóigica', 'lûóigica', 'lùóigica', 'lũóigica', 'lçóigica', 'lóaigica', 'lóbigica', 'lócigica', 'lódigica', 'lóeigica', 'lófigica', 'lógigica', 'lóhigica', 'lóiigica', 'lójigica', 'lókigica', 'lóligica', 'lómigica', 'lónigica', 'lóoigica', 'lópigica', 'lóqigica', 'lórigica', 'lósigica', 'lótigica', 'lóuigica', 'lóvigica', 'lówigica', 'lóxigica', 'lóyigica', 'lózigica', 'lóáigica', 'lóâigica', 'lóàigica', 'lóãigica', 'lóéigica', 'lóêigica', 'lóèigica', 'lóẽigica', 'lóíigica', 'lóîigica', 'lóìigica', 'lóĩigica', 'lóóigica', 'lóôigica', 'lóõigica', 'lóòigica', 'lóúigica', 'lóûigica', 'lóùigica', 'lóũigica', 'lóçigica', 'lóiagica', 'lóibgica', 'lóicgica', 'lóidgica', 'lóiegica', 'lóifgica', 'lóiggica', 'lóihgica', 'lóiigica', 'lóijgica', 'lóikgica', 'lóilgica', 'lóimgica', 'lóingica', 'lóiogica', 'lóipgica', 'lóiqgica', 'lóirgica', 'lóisgica', 'lóitgica', 'lóiugica', 'lóivgica', 'lóiwgica', 'lóixgica', 'lóiygica', 'lóizgica', 'lóiágica', 'lóiâgica', 'lóiàgica', 'lóiãgica', 'lóiégica', 'lóiêgica', 'lóiègica', 'lóiẽgica', 'lóiígica', 'lóiîgica', 'lóiìgica', 'lóiĩgica', 'lóiógica', 'lóiôgica', 'lóiõgica', 'lóiògica', 'lóiúgica', 'lóiûgica', 'lóiùgica', 'lóiũgica', 'lóiçgica', 'lóigaica', 'lóigbica', 'lóigcica', 'lóigdica', 'lóigeica', 'lóigfica', 'lóiggica', 'lóighica', 'lóigiica', 'lóigjica', 'lóigkica', 'lóiglica', 'lóigmica', 'lóignica', 'lóigoica', 'lóigpica', 'lóigqica', 'lóigrica', 'lóigsica', 'lóigtica', 'lóiguica', 'lóigvica', 'lóigwica', 'lóigxica', 'lóigyica', 'lóigzica', 'lóigáica', 'lóigâica', 'lóigàica', 'lóigãica', 'lóigéica', 'lóigêica', 'lóigèica', 'lóigẽica', 'lóigíica', 'lóigîica', 'lóigìica', 'lóigĩica', 'lóigóica', 'lóigôica', 'lóigõica', 'lóigòica', 'lóigúica', 'lóigûica', 'lóigùica', 'lóigũica', 'lóigçica', 'lóigiaca', 'lóigibca', 'lóigicca', 'lóigidca', 'lóigieca', 'lóigifca', 'lóigigca', 'lóigihca', 'lóigiica', 'lóigijca', 'lóigikca', 'lóigilca', 'lóigimca', 'lóiginca', 'lóigioca', 'lóigipca', 'lóigiqca', 'lóigirca', 'lóigisca', 'lóigitca', 'lóigiuca', 'lóigivca', 'lóigiwca', 'lóigixca', 'lóigiyca', 'lóigizca', 'lóigiáca', 'lóigiâca', 'lóigiàca', 'lóigiãca', 'lóigiéca', 'lóigiêca', 'lóigièca', 'lóigiẽca', 'lóigiíca', 'lóigiîca', 'lóigiìca', 'lóigiĩca', 'lóigióca', 'lóigiôca', 'lóigiõca', 'lóigiòca', 'lóigiúca', 'lóigiûca', 'lóigiùca', 'lóigiũca', 'lóigiçca', 'lóigicaa', 'lóigicba', 'lóigicca', 'lóigicda', 'lóigicea', 'lóigicfa', 'lóigicga', 'lóigicha', 'lóigicia', 'lóigicja', 'lóigicka', 'lóigicla', 'lóigicma', 'lóigicna', 'lóigicoa', 'lóigicpa', 'lóigicqa', 'lóigicra', 'lóigicsa', 'lóigicta', 'lóigicua', 'lóigicva', 'lóigicwa', 'lóigicxa', 'lóigicya', 'lóigicza', 'lóigicáa', 'lóigicâa', 'lóigicàa', 'lóigicãa', 'lóigicéa', 'lóigicêa', 'lóigicèa', 'lóigicẽa', 'lóigicía', 'lóigicîa', 'lóigicìa', 'lóigicĩa', 'lóigicóa', 'lóigicôa', 'lóigicõa', 'lóigicòa', 'lóigicúa', 'lóigicûa', 'lóigicùa', 'lóigicũa', 'lóigicça', 'lóigicaa', 'lóigicab', 'lóigicac', 'lóigicad', 'lóigicae', 'lóigicaf', 'lóigicag', 'lóigicah', 'lóigicai', 'lóigicaj', 'lóigicak', 'lóigical', 'lóigicam', 'lóigican', 'lóigicao', 'lóigicap', 'lóigicaq', 'lóigicar', 'lóigicas', 'lóigicat', 'lóigicau', 'lóigicav', 'lóigicaw', 'lóigicax', 'lóigicay', 'lóigicaz', 'lóigicaá', 'lóigicaâ', 'lóigicaà', 'lóigicaã', 'lóigicaé', 'lóigicaê', 'lóigicaè', 'lóigicaẽ', 'lóigicaí', 'lóigicaî', 'lóigicaì', 'lóigicaĩ', 'lóigicaó', 'lóigicaô', 'lóigicaõ', 'lóigicaò', 'lóigicaú', 'lóigicaû', 'lóigicaù', 'lóigicaũ', 'lóigicaç', 'óigica', 'ligica', 'lógica', 'lóiica', 'lóigca', 'lóigia', 'lóigic', 'lóigica']\n"
     ]
    }
   ],
   "source": [
    "word_example = \"lóigica\"\n",
    "generated_words = words_generator(word_example)\n",
    "print(generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "w6VunyjBhIs2",
    "outputId": "dc70bf31-e906-49f4-d965-8a4b30272233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.4% of 186 words\n"
     ]
    }
   ],
   "source": [
    "evaluator(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making more words variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "bcs80q9DiwS0",
    "outputId": "fe2f931d-7167-45fb-8313-c10b92b84f6d"
   },
   "outputs": [],
   "source": [
    "def insert_letters(slices):\n",
    "    new_words = []\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
    "    for left, right in slices:\n",
    "        for letter in letters:\n",
    "            new_words.append(left + letter + right)\n",
    "    return new_words\n",
    "\n",
    "def deleting_character(slices):\n",
    "    new_words = []\n",
    "    for left, right in slices:\n",
    "        new_words.append(left + right[1:])\n",
    "    return new_words\n",
    "\n",
    "def change_letter(slices):\n",
    "    new_words = []\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
    "    for left, right in slices:\n",
    "        for letter in letters:\n",
    "            new_words.append(left + letter + right[1:])\n",
    "    return new_words\n",
    "\n",
    "def inverte_letter(slices):\n",
    "    new_words = []\n",
    "    for left, right in slices:\n",
    "        if len(right) > 1:\n",
    "            new_words.append(left + right[1] + right[0] + right[2:])\n",
    "    return new_words\n",
    "\n",
    "def words_generator(word):\n",
    "    slices = []\n",
    "    for i in range(len(word)+1):\n",
    "        slices.append((word[:i],word[i:]))\n",
    "    generated_words = insert_letters(slices)\n",
    "    generated_words += deleting_character(slices)\n",
    "    generated_words += change_letter(slices)\n",
    "    generated_words += inverte_letter(slices)\n",
    "    return generated_words\n",
    "\n",
    "def spell_checker(word):\n",
    "    generated_words = words_generator(word)\n",
    "    corrected_word = max(generated_words, key=probability)\n",
    "    return corrected_word\n",
    "\n",
    "def evaluator(tests):\n",
    "    word_number = len(tests)\n",
    "    got_right = 0\n",
    "    for correct, wrong in tests:\n",
    "        corrected_word = spell_checker(wrong)\n",
    "        if corrected_word == correct:\n",
    "            got_right += 1\n",
    "    hit_rate = round(got_right*100/word_number, 2)\n",
    "    print(f\"{hit_rate}% of {word_number} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34% of 186 words\n"
     ]
    }
   ],
   "source": [
    "evaluator(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of the rate of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rbPWQCKhqT-P",
    "outputId": "7052f9e0-d2c5-4fd8-9242-bc429639534e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34% of 186 words, unkown is 6.99%\n"
     ]
    }
   ],
   "source": [
    "def evaluator(tests, vocabulary):\n",
    "    words_number = len(tests)\n",
    "    got_right = 0\n",
    "    unkown = 0\n",
    "    for right, wrong in tests:\n",
    "        corrected_word = spell_checker(wrong)\n",
    "        if corrected_word == right:\n",
    "            got_right += 1\n",
    "        else:\n",
    "            unkown += (right not in vocabulary)    \n",
    "    right_rate = round(got_right*100/words_number, 2)\n",
    "    unknown_rate = round(unkown*100/words_number, 2)\n",
    "    print(f\"{right_rate}% of {words_number} words, unkown is {unknown_rate}%\")\n",
    "\n",
    "vocabulary = set(normalized_list)\n",
    "evaluator(test_list, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a turbine generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LY-lTv4E6sP0",
    "outputId": "b9692ec5-733e-4ae7-8a2b-35d9d7ed5c67"
   },
   "outputs": [],
   "source": [
    "# This function will return a correct word in a distance of 2 from the words spelled wrongly\n",
    "# Apply twice the words_generator\n",
    "def turbine_generator(generated_words):\n",
    "    new_words = []\n",
    "    for word in generated_words:\n",
    "        new_words += words_generator(word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"lóiigica\"\n",
    "all_words_generated = turbine_generator(words_generator(word))\n",
    "# check if the right words is in the generated list of words\n",
    "\"lógica\" in all_words_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0cmkyrsMKH5c",
    "outputId": "8c52131f-5c21-4136-f9dc-4d901df262ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "787396"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generates a lot of words if just one wrong word. So this is not efficient\n",
    "len(all_words_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new spell checker, avoiding unnecessary words generated in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_DM1WYg7KamU",
    "outputId": "dcda7c07-bd64-4e2c-fb7a-c7d4d2dd8f04"
   },
   "outputs": [],
   "source": [
    "def new_spell_checker(word):\n",
    "    generated_words = words_generator(word)\n",
    "    turbinated_words = turbine_generator(generated_words)\n",
    "    all_words = set(generated_words + turbinated_words)\n",
    "    # If I can corret this words it is returned this word\n",
    "    candidates = [word]\n",
    "    for word in all_words:\n",
    "        if word in vocabulary:\n",
    "            candidates.append(word)\n",
    "    corrected_word = max(candidates, key=probability)\n",
    "    return corrected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"lóiigica\"\n",
    "new_spell_checker(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hZ6G5jMaZUfZ",
    "outputId": "0624930e-d7eb-4122-cbd3-a1ced5059e4d"
   },
   "outputs": [],
   "source": [
    "def evaluator(tests, vocabulary):\n",
    "    words_number = len(tests)\n",
    "    got_right = 0\n",
    "    unkown = 0\n",
    "    for right, wrong in tests:\n",
    "        corrected_word = new_spell_checker(wrong)\n",
    "        unkown += (right not in vocabulary)\n",
    "        if corrected_word == right:\n",
    "            got_right += 1\n",
    "        # This else is in a wrong place. The unknown words does not depend if the word is corrected or not\n",
    "        else:\n",
    "            print(wrong + \"-\" + spell_checker(wrong) + \"-\" + corrected_word)\n",
    "    right_rate = round(got_right*100/words_number, 2)\n",
    "    unknown_rate = round(unkown*100/words_number, 2)\n",
    "    print(f\"{right_rate}% of {words_number} words, unkown is {unknown_rate}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(tests, vocabulary):\n",
    "    words_number = len(tests)\n",
    "    got_right = 0\n",
    "    unkown = 0\n",
    "    for right, wrong in tests:\n",
    "        corrected_word = new_spell_checker(wrong)\n",
    "        unknow += (right not in vocabulary) # right place\n",
    "        if corrected_word == right:\n",
    "            got_right += 1\n",
    "        # This unknow is in a wrong place. The unknown words does not depend if the word is corrected or not\n",
    "        else:\n",
    "            #unknow += (right not in vocabulary) \n",
    "            print(wrong + \"-\" + spell_checker(wrong) + \"-\" + corrected_word)\n",
    "    right_rate = round(got_right*100/words_number, 2)\n",
    "    unknown_rate = round(unknow*100/words_number, 2)\n",
    "    print(f\"{right_rate}% of {words_number} words, unkown is {unknown_rate}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esje-esse-se\n",
      "sãêo-são-não\n",
      "dosa-dos-do\n",
      "eme-em-de\n",
      "eàssa-essa-esse\n",
      "daõs-das-da\n",
      "céda-cada-da\n",
      "noâ-no-o\n",
      "enêão-então-não\n",
      "tĩem-tem-em\n",
      "nossah-nossa-nosso\n",
      "teb-tem-de\n",
      "atĩ-até-a\n",
      "âem-em-de\n",
      "foo-foi-o\n",
      "serr-ser-se\n",
      "entke-entre-então\n",
      "van-vai-a\n",
      "çeus-seus-seu\n",
      "eû-e-de\n",
      "temeo-tempo-temos\n",
      "semre-sempre-ser\n",
      "elaá-ela-ele\n",
      "síó-só-se\n",
      "siàe-site-se\n",
      "seém-sem-em\n",
      "peln-pelo-ele\n",
      "aléra-alura-agora\n",
      "tdia-dia-da\n",
      "tuúo-tudo-tipo\n",
      "jé-é-de\n",
      "sãô-são-não\n",
      "odos-dos-do\n",
      "siua-sua-seu\n",
      "elpe-ele-esse\n",
      "teos-temos-os\n",
      "eũsa-essa-esse\n",
      "vjmos-vamos-temos\n",
      "dms-dos-de\n",
      "cava-java-para\n",
      "ános-nos-no\n",
      "èaso-caso-as\n",
      "túem-tem-em\n",
      "daáos-dados-dos\n",
      "nossk-nosso-nosso\n",
      "tãer-ter-ser\n",
      "vté-até-é\n",
      "búm-bem-um\n",
      "sçerá-será-ser\n",
      "entró-entre-então\n",
      "uai-vai-a\n",
      "sâus-seus-seu\n",
      "ìeu-seu-de\n",
      "fual-qual-sua\n",
      "elal-ela-ele\n",
      "skó-só-se\n",
      "secm-sem-em\n",
      "aluéa-alura-além\n",
      "dil-dia-de\n",
      "sód-só-se\n",
      "eúaa-aeúaa-essa\n",
      "ró-só-de\n",
      "dĩaz-adĩaz-da\n",
      "correptor-corretor-correto\n",
      "trtica-tática-prática\n",
      "ewpoderamento-aewpoderamento-ewpoderamento\n",
      "îgato-gato-fato\n",
      "cakvalo-acakvalo-carvalho\n",
      "canelac-acanelac-janela\n",
      "tênisy-atênisy-tênisy\n",
      "anciosa-aanciosa-ansioso\n",
      "ancciosa-aancciosa-ancciosa\n",
      "ansioa-aansioa-ensina\n",
      "asterístico-aasterístico-asterístico\n",
      "entertido-aentertido-entendido\n",
      "ritimo-ritmo-ótimo\n",
      "indiota-aindiota-indica\n",
      "tomare-tomar-tomar\n",
      "seje-seja-se\n",
      "provalecer-aprovalecer-prevaleceu\n",
      "esteje-esteja-este\n",
      "mindigo-amindigo-indico\n",
      "pertubar-apertubar-derrubar\n",
      "55.38% of 186 words, unkown is 6.99%\n"
     ]
    }
   ],
   "source": [
    "# See the wrong word, word passed to the spell checker and the right word\n",
    "# The performance decrease\n",
    "vocabulary = set(normalized_list)\n",
    "evaluator(test_list, vocabulary) # the new evaluator corrects a lot the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance decrease because in the set of the words the wrong answers are to 1 distance to the right word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jWWR0FFgbTJ1",
    "outputId": "2de33bdc-7959-4e4d-d852-c64b0b5dc7f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34% de 186 palavras, unkown é 6.99%\n"
     ]
    }
   ],
   "source": [
    "# The better one for this set of data\n",
    "def evaluator(tests, vocabulary):\n",
    "    words_number = len(tests)\n",
    "    got_right = 0\n",
    "    unkown = 0\n",
    "    for right, wrong in tests:\n",
    "        corrected_word = spell_checker(wrong)\n",
    "        unkown += (right not in vocabulary)\n",
    "        if corrected_word == right:\n",
    "            got_right += 1 \n",
    "    right_rate = round(got_right*100/words_number, 2)\n",
    "    unknown_rate = round(unkown*100/words_number, 2)\n",
    "    print(f\"{right_rate}% de {words_number} palavras, unkown é {unknown_rate}%\")\n",
    "\n",
    "vocabulary = set(normalized_list)\n",
    "evaluator(test_list, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "DiV344QAeWif",
    "outputId": "95e7366b-012d-4d54-d9f6-b24143266057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lógica\n",
      "alóiigica\n"
     ]
    }
   ],
   "source": [
    "word = \"lóiigica\"\n",
    "print(new_spell_checker(word))\n",
    "print(spell_checker(word))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Corretor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
